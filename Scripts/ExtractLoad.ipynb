{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Extract data and load it into bucket'\n","- Much of the code here comes from https://github.com/MengtingWan/goodreads/blob/master/download.ipynb. The code here has been modified to fit the purpose of this project\n","- Credit goes to Mengting Wan from https://github.com/MengtingWan for providing the data and reference jupyter notebook files to examine and download the data"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import gzip\n","import requests\n","from google.cloud import storage\n","import os\n","import shutil"]},{"cell_type":"markdown","metadata":{},"source":["**Specify your directory and bucket here:**"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["DIR = './home'\n","bucket_name = 'goodreads_bucket'"]},{"cell_type":"markdown","metadata":{},"source":["**Load data types and names**"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (2627832139.py, line 37)","output_type":"error","traceback":["\u001B[0;36m  Cell \u001B[0;32mIn[13], line 37\u001B[0;36m\u001B[0m\n\u001B[0;31m    (\"complete\", \"goodreads_reviews_spoiler_raw.json.gz\"),|\u001B[0m\n\u001B[0m                                                          ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"]}],"source":["# Define the data as a list of tuples (type, name)\n","data = [\n","    (\"complete\", \"goodreads_book_works.json.gz\"),\n","    (\"complete\", \"goodreads_book_authors.json.gz\"),\n","    (\"complete\", \"goodreads_book_series.json.gz\"),\n","    (\"complete\", \"goodreads_books.json.gz\"),\n","    (\"complete\", \"goodreads_book_genres_initial.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_children.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_comics_graphic.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_fantasy_paranormal.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_history_biography.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_mystery_thriller_crime.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_poetry.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_romance.json.gz\"),\n","    (\"byGenre\", \"goodreads_books_young_adult.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_children.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_comics_graphic.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_fantasy_paranormal.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_history_biography.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_mystery_thriller_crime.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_poetry.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_romance.json.gz\"),\n","    (\"byGenre\", \"goodreads_interactions_young_adult.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_children.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_comics_graphic.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_fantasy_paranormal.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_history_biography.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_mystery_thriller_crime.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_poetry.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_romance.json.gz\"),\n","    (\"byGenre\", \"goodreads_reviews_young_adult.json.gz\"),\n","    (\"complete\", \"book_id_map.csv\"),\n","    (\"complete\", \"user_id_map.csv\"),\n","    (\"complete\", \"goodreads_interactions.csv\"),\n","    (\"complete\", \"goodreads_reviews_dedup.json.gz\"),\n","    (\"complete\", \"goodreads_reviews_spoiler.json.gz\"),\n","    (\"complete\", \"goodreads_reviews_spoiler_raw.json.gz\"),|\n","    (\"complete\", \"goodreads_interactions_dedup.json.gz\")\n","]\n","\n","# Create the DataFrame\n","file_names = pd.DataFrame(data, columns=[\"type\", \"name\"])\n","\n","# Display the DataFrame\n","display(file_names)"]},{"cell_type":"markdown","metadata":{},"source":["**Now we can construct the urls to download files by name**"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["file_name_type_mapping = dict(zip(file_names['name'].values, file_names['type'].values))\n","file_name_url_mapping = {}\n","\n","for fname in file_name_type_mapping:\n","    ftype = file_name_type_mapping[fname]\n","    if ftype == \"complete\":\n","        url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/'+fname\n","        file_name_url_mapping[fname] = url\n","    elif ftype == \"byGenre\":\n","        url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/byGenre/'+fname\n","        file_name_url_mapping[fname] = url"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def download_and_upload(fname, local_filename, gcs_blob_name):\n","    if fname in file_name_url_mapping:\n","        url = file_name_url_mapping[fname]\n","        # Download the file locally\n","        with requests.get(url, stream=True) as r:\n","            r.raise_for_status()\n","            with open(local_filename, 'wb') as f:\n","                for chunk in r.iter_content(chunk_size=8192):\n","                    f.write(chunk)\n","        print('Dataset', fname, 'has been downloaded!')\n","\n","        # Check if the file is a .gz file\n","        if local_filename.endswith('.gz'):\n","            extracted_filename = local_filename[:-3]  # Remove .gz extension\n","            try:\n","                # Extract the .gz file\n","                with gzip.open(local_filename, 'rb') as gz_file:\n","                    with open(extracted_filename, 'wb') as extracted_file:\n","                        shutil.copyfileobj(gz_file, extracted_file)\n","                print(f'File {local_filename} has been extracted to {extracted_filename}.')\n","                \n","                # Update local filename to the extracted file\n","                local_filename = extracted_filename\n","                # Update the GCS blob name to reflect the extracted file\n","                gcs_blob_name = gcs_blob_name[:-3]\n","            except Exception as e:\n","                print(f'Failed to extract .gz file: {e}')\n","                return\n","\n","        # Upload the file to Google Cloud Storage in the \"landing\" folder\n","        try:\n","            storage_client = storage.Client()\n","            bucket = storage_client.bucket(bucket_name)\n","            blob = bucket.blob(f'landing/{gcs_blob_name}')\n","            blob.upload_from_filename(local_filename)\n","            print(f'File {local_filename} uploaded to bucket {bucket_name} under folder landing as landing/{gcs_blob_name}.')\n","        except Exception as e:\n","            print(f'Failed to upload file to GCS: {e}')\n","    else:\n","        print('Dataset', fname, 'cannot be found!')"]},{"cell_type":"markdown","metadata":{},"source":["**Here we go!**"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Specify the directory we want to save the data to locally, and also the name of the file\n","OUT_DIR = './extracted_data_from_goodreads'"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset goodreads_reviews_dedup.json.gz has been downloaded!\n","File ./extracted_data_from_goodreads/goodreads_reviews_dedup.json.gz has been extracted to ./extracted_data_from_goodreads/goodreads_reviews_dedup.json.\n","File ./extracted_data_from_goodreads/goodreads_reviews_dedup.json uploaded to bucket goodreads_bucket under folder landing as landing/goodreads_reviews_dedup.json.\n"]}],"source":["# We want these files\n","# - goodreads_reviews_dedup.json.gz\n","# - goodreads_books.json.gz\n","# - goodreads_interactions.csv\n","\n","file_name = 'goodreads_reviews_dedup.json.gz'\n","\n","\n","if not os.path.exists(OUT_DIR):\n","    os.makedirs(OUT_DIR)\n","\n","output_path = os.path.join(OUT_DIR, file_name)\n","download_and_upload(file_name, output_path, file_name)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset goodreads_books.json.gz has been downloaded!\n","File ./extracted_data_from_goodreads/goodreads_books.json.gz has been extracted to ./extracted_data_from_goodreads/goodreads_books.json.\n","File ./extracted_data_from_goodreads/goodreads_books.json uploaded to bucket goodreads_bucket under folder landing as landing/goodreads_books.json.\n"]}],"source":["# Specify the name of the file\n","file_name = 'goodreads_books.json.gz'\n","\n","\n","if not os.path.exists(OUT_DIR):\n","    os.makedirs(OUT_DIR)\n","\n","output_path = os.path.join(OUT_DIR, file_name)\n","download_and_upload(file_name, output_path, file_name)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset goodreads_interactions.csv has been downloaded!\n","File ./extracted_data_from_goodreads/goodreads_interactions.csv uploaded to bucket goodreads_bucket under folder landing as landing/goodreads_interactions.csv.\n"]}],"source":["# Specify the name of the file\n","file_name = 'goodreads_interactions.csv'\n","\n","\n","if not os.path.exists(OUT_DIR):\n","    os.makedirs(OUT_DIR)\n","\n","output_path = os.path.join(OUT_DIR, file_name)\n","download_and_upload(file_name, output_path, file_name)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset goodreads_book_genres_initial.json.gz has been downloaded!\n","File ./extracted_data_from_goodreads/goodreads_book_genres_initial.json.gz has been extracted to ./extracted_data_from_goodreads/goodreads_book_genres_initial.json.\n","File ./extracted_data_from_goodreads/goodreads_book_genres_initial.json uploaded to bucket goodreads_bucket under folder landing as landing/goodreads_book_genres_initial.json.\n"]}],"source":["# Specify the name of the file\n","file_name = 'goodreads_book_genres_initial.json.gz'\n","\n","\n","if not os.path.exists(OUT_DIR):\n","    os.makedirs(OUT_DIR)\n","\n","output_path = os.path.join(OUT_DIR, file_name)\n","download_and_upload(file_name, output_path, file_name)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset goodreads_book_authors.json.gz has been downloaded!\n","File ./extracted_data_from_goodreads/goodreads_book_authors.json.gz has been extracted to ./extracted_data_from_goodreads/goodreads_book_authors.json.\n","File ./extracted_data_from_goodreads/goodreads_book_authors.json uploaded to bucket goodreads_bucket under folder landing as landing/goodreads_book_authors.json.\n"]}],"source":["# Specify the name of the file\n","file_name = 'goodreads_book_authors.json.gz'\n","\n","\n","if not os.path.exists(OUT_DIR):\n","    os.makedirs(OUT_DIR)\n","\n","output_path = os.path.join(OUT_DIR, file_name)\n","download_and_upload(file_name, output_path, file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":2}